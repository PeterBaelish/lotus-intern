#### 背景

GPU不支持抢占，GPU访问请求被按序处理，这是由于GPU上下文切换的开销很大。并且GPU driver不考虑系统中任务的优先级和调度策略。

将GPU任务分解为 一般执行块 和 GPU访问块，一般访问块全部在CPU上执行，GPU访问块包含了GPU操作

![image-20220608142106144](C:\Users\Ziyang.Tao\AppData\Roaming\Typora\typora-user-images\image-20220608142106144.png)

注：数据拷贝用DMA技术。在数据拷贝、GPU执行时，任务会挂起或忙等待。

同步GPU访问：GPU指令必须等待前一个执行完才能执行。

异步GPU访问：CPU、GPU计算可以并行。如CUDA、OpenCL

前人的工作是基于同步的方法。该方法对GPU资源隔离，使用实时同步协议来仲裁GPU使用权。然而，由于这种方法的基本假设是在临界区，因此要求任务在整个GPU执行过程中都处于忙等待状态，从而导致大量的CPU利用率损失。 并且实时同步协议包含优先级提升机制，会延缓高优先级任务的执行。

具体而言，基于同步的方法将GPU视为互斥的单元，并且将GPU访问块视为临界区，用一个互斥锁保护这个GPU临界区。试图获取已经被占用的互斥锁的任务将被挂起。互斥锁可以更细粒度，如GPUSync用不同的锁来保护数据复制模块和执行模块，来达到更高的并行度。

实时同步协议有很多种，这里考虑多处理器优先级上限协议(Multiprocessor Priority Ceiling Protocol，MPCP)，协议内容如下：

- 当任务需要资源时且资源没有被其他任务占用时，直接被赋予给该任务
- 当一个任务持有分配给不同核心的任务的共享资源时，这个任务的优先级提高到$\pi_B + \pi_i$ 。其中$\pi_B$是基础任务优先级，这个优先级比系统中的任何任务的优先级都高，$\pi_i$是任务本身的优先级。这种优先级提升机制用来防止无界优先级反转**(?)**。

- 如果任务需要的资源被其他任务占用，那么任务被插入该资源的互斥锁的等待队列，并且任务挂起
- 资源释放时，如果资源的互斥锁的等待队列非空，那么取等待队列的最高优先级的任务将资源分配给该任务

优先级提升会导致 长期优先级反转的问题。

![image-20220608151847693](C:\Users\Ziyang.Tao\AppData\Roaming\Typora\typora-user-images\image-20220608151847693.png)

注：上图中任务优先级从上到下依次从高到低。



#### 改进方法

提出基于服务的方法，设计一个专用于GPU服务的任务接收并处理其他GPU请求。不同于基于同步的方法，基于服务的方法支持任务在GPU执行过程中挂起，同时保留分析能力。

CPU调度方案：分区固定优先级抢占式任务调度，此调度方法不涉及任务的CPU核迁移。

具体来说，创建一个GPU服务任务来接收其他任务的GPU访问请求。服务任务拥有系统中最高的优先级以确保避免被抢占。

![image-20220608155953612](C:\Users\Ziyang.Tao\AppData\Roaming\Typora\typora-user-images\image-20220608155953612.png)

任务的GPU访问请求到来时，它向GPU服务任务发送一个请求，该请求是通过向服务任务发送GPU访问段的内存区域信息，包括执行GPU内核的输入/输出数据、命令和代码。这需要将内存区域配置为共享区域，以便GPU服务任务有可以通过它们的标识符访问它们，例如shmid。任务在发送完请求后挂起

如果GPU正在被其他任务使用，则服务任务将这些请求加入GPU请求队列中，这个队列是一个优先队列。

GPU不再被占用时，服务程序从队列头部取任务执行。在CPU闲置时间内（如数据复制、GPU执行），在同步模式下，服务任务自己被挂起；异步模式下，服务任务执行其他请求的CPU操作，并且在完成他们之后挂起。

当请求完成时，服务任务通知对应的任务并将其唤醒。最后原任务继续执行。

改进方法会引进新的时间开销：发送GPU请求、唤醒服务任务、请求排队、检查最高优先级任务、通知请求完成。用 $\varepsilon$ 表示这些额外时间开销的上限。

![image-20220608163716186](C:\Users\Ziyang.Tao\AppData\Roaming\Typora\typora-user-images\image-20220608163716186.png)

该方法解决了忙等待和优先级反转的问题。



